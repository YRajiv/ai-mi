{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYSmQIqEqgMcqztALJxOey",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YRajiv/ai-mi/blob/main/lab_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzdl0fqGNMyM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc(\"font\", size=14)\n",
        "import seaborn as sns\n",
        "sns.set(style=\"white\") #white background style for seaborn plots\n",
        "sns.set(style=\"whitegrid\", color_codes=True)\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df = pd.read_csv(\"titanic_train.csv\")\n",
        "test_df = pd.read_csv(\"titanic_test.csv\")\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "5CIaalSBNpr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The number of samples into the train data is {}.'.format(train_df.shape[0]))\n"
      ],
      "metadata": {
        "id": "zd-SBP4dNuCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preview test data\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "QHwRotA0Nz6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The number of samples into the test data is {}.'.format(test_df.shape[0]))"
      ],
      "metadata": {
        "id": "Y20Nl1Q9N5b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check missing values in train data\n",
        "train_df.isnull().sum()"
      ],
      "metadata": {
        "id": "UBP2z43wN9L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# percent of missing \"Age\"\n",
        "print('Percent of missing \"Age\" records is %.2f%%' %((train_df['Age'].isnull().sum()/train_df.shape[0])*100))"
      ],
      "metadata": {
        "id": "LMgIbpFzN-I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = train_df[\"Age\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
        "train_df[\"Age\"].plot(kind='density', color='teal')\n",
        "ax.set(xlabel='Age')\n",
        "plt.xlim(-10,85)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0SLZcPj6OC2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mean age\n",
        "print('The mean of \"Age\" is %.2f' %(train_df[\"Age\"].mean(skipna=True)))\n",
        "# median age\n",
        "print('The median of \"Age\" is %.2f' %(train_df[\"Age\"].median(skipna=True)))"
      ],
      "metadata": {
        "id": "0euEzqAeOD3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# percent of missing \"Cabin\"\n",
        "print('Percent of missing \"Cabin\" records is %.2f%%' %((train_df['Cabin'].isnull().sum()/train_df.shape[0])*100))"
      ],
      "metadata": {
        "id": "8DOx2FqfOIAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# percent of missing \"Embarked\"\n",
        "print('Percent of missing \"Embarked\" records is %.2f%%' %((train_df['Embarked'].isnull().sum()/train_df.shape[0])*100))"
      ],
      "metadata": {
        "id": "Rc3AGdOjOLma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Boarded passengers grouped by port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton):')\n",
        "print(train_df['Embarked'].value_counts())\n",
        "sns.countplot(x='Embarked', data=train_df, palette='Set2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mrbgA_-SOPCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The most common boarding port of embarkation is %s.' %train_df['Embarked'].value_counts().idxmax())"
      ],
      "metadata": {
        "id": "bcLhck7rOTo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_df.copy()\n",
        "train_data[\"Age\"].fillna(train_df[\"Age\"].median(skipna=True), inplace=True)\n",
        "train_data[\"Embarked\"].fillna(train_df['Embarked'].value_counts().idxmax(), inplace=True)\n",
        "train_data.drop('Cabin', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "tZhQUQMaOX0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check missing values in adjusted train data\n",
        "train_data.isnull().sum()"
      ],
      "metadata": {
        "id": "Ohhy4CyrOa7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preview adjusted train data\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "mQNO_mMhOfV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "ax = train_df[\"Age\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
        "train_df[\"Age\"].plot(kind='density', color='teal')\n",
        "ax = train_data[\"Age\"].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.5)\n",
        "train_data[\"Age\"].plot(kind='density', color='orange')\n",
        "ax.legend(['Raw Age', 'Adjusted Age'])\n",
        "ax.set(xlabel='Age')\n",
        "plt.xlim(-10,85)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AhnsfFXEOtWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create categorical variable for traveling alone\n",
        "train_data['TravelAlone']=np.where((train_data[\"SibSp\"]+train_data[\"Parch\"])>0, 0, 1)\n",
        "train_data.drop('SibSp', axis=1, inplace=True)\n",
        "train_data.drop('Parch', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "G6_bPaXXOxhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create categorical variables and drop some variables\n",
        "training=pd.get_dummies(train_data, columns=[\"Pclass\",\"Embarked\",\"Sex\"])\n",
        "training.drop('Sex_female', axis=1, inplace=True)\n",
        "training.drop('PassengerId', axis=1, inplace=True)\n",
        "training.drop('Name', axis=1, inplace=True)\n",
        "training.drop('Ticket', axis=1, inplace=True)\n",
        "\n",
        "final_train = training\n",
        "final_train.head()"
      ],
      "metadata": {
        "id": "LMsXq1_1OyUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.isnull().sum()"
      ],
      "metadata": {
        "id": "uwWmsf6cO01_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test_df.copy()\n",
        "test_data[\"Age\"].fillna(train_df[\"Age\"].median(skipna=True), inplace=True)\n",
        "test_data[\"Fare\"].fillna(train_df[\"Fare\"].median(skipna=True), inplace=True)\n",
        "test_data.drop('Cabin', axis=1, inplace=True)\n",
        "\n",
        "test_data['TravelAlone']=np.where((test_data[\"SibSp\"]+test_data[\"Parch\"])>0, 0, 1)\n",
        "\n",
        "test_data.drop('SibSp', axis=1, inplace=True)\n",
        "test_data.drop('Parch', axis=1, inplace=True)\n",
        "\n",
        "testing = pd.get_dummies(test_data, columns=[\"Pclass\",\"Embarked\",\"Sex\"])\n",
        "testing.drop('Sex_female', axis=1, inplace=True)\n",
        "testing.drop('PassengerId', axis=1, inplace=True)\n",
        "testing.drop('Name', axis=1, inplace=True)\n",
        "testing.drop('Ticket', axis=1, inplace=True)\n",
        "\n",
        "final_test = testing\n",
        "final_test.head()"
      ],
      "metadata": {
        "id": "Ij5gnTgGPFGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "ax = sns.kdeplot(final_train[\"Age\"][final_train.Survived == 1], color=\"darkturquoise\", shade=True)\n",
        "sns.kdeplot(final_train[\"Age\"][final_train.Survived == 0], color=\"lightcoral\", shade=True)\n",
        "plt.legend(['Survived', 'Died'])\n",
        "plt.title('Density Plot of Age for Surviving Population and Deceased Population')\n",
        "ax.set(xlabel='Age')\n",
        "plt.xlim(-10,85)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7VlCQLSJPGYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "avg_survival_byage = final_train[[\"Age\", \"Survived\"]].groupby(['Age'], as_index=False).mean()\n",
        "g = sns.barplot(x='Age', y='Survived', data=avg_survival_byage, color=\"LightSeaGreen\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KUTeRNBnPKV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_train['IsMinor']=np.where(final_train['Age']<=16, 1, 0)\n",
        "\n",
        "final_test['IsMinor']=np.where(final_test['Age']<=16, 1, 0)\n",
        "\n"
      ],
      "metadata": {
        "id": "i-EXsmS5PRec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "ax = sns.kdeplot(final_train[\"Fare\"][final_train.Survived == 1], color=\"darkturquoise\", shade=True)\n",
        "sns.kdeplot(final_train[\"Fare\"][final_train.Survived == 0], color=\"lightcoral\", shade=True)\n",
        "plt.legend(['Survived', 'Died'])\n",
        "plt.title('Density Plot of Fare for Surviving Population and Deceased Population')\n",
        "ax.set(xlabel='Fare')\n",
        "plt.xlim(-20,200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QZrwuHqgPSzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Pclass', y='Survived', data=train_df, color=\"darkturquoise\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZG5uWUmMPWMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Embarked', y='Survived', data=train_df, color=\"teal\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Osmhu-VtPcis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='TravelAlone',y= 'Survived', data=final_train, color=\"mediumturquoise\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qeh_TShpPg-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Sex',y= 'Survived', data=train_df, color=\"aquamarine\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uRb8I35NPn3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "cols = [\"Age\",\"Fare\",\"TravelAlone\",\"Pclass_1\",\"Pclass_2\",\"Embarked_C\",\"Embarked_S\",\"Sex_male\",\"IsMinor\"]\n",
        "X = final_train[cols]\n",
        "y = final_train['Survived']\n",
        "# Build a logreg and compute the feature importances\n",
        "model = LogisticRegression()\n",
        "# create the RFE model and select 8 attributes\n",
        "rfe = RFE(model, n_features_to_select=8) # Pass n_features_to_select as a keyword argument\n",
        "rfe = rfe.fit(X, y)\n",
        "# summarize the selection of the attributes\n",
        "print('Selected features: %s' % list(X.columns[rfe.support_]))"
      ],
      "metadata": {
        "id": "2OFbl6NrPr_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "# Create the RFE object and compute a cross-validated score.\n",
        "# The \"accuracy\" scoring is proportional to the number of correct classifications\n",
        "rfecv = RFECV(estimator=LogisticRegression(), step=1, cv=10, scoring='accuracy')\n",
        "rfecv.fit(X, y)\n",
        "\n",
        "print(\"Optimal number of features: %d\" % rfecv.n_features_)\n",
        "print('Selected features: %s' % list(X.columns[rfecv.support_]))\n",
        "\n",
        "# Plot number of features VS. cross-validation scores\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "# Access the cross-validation scores using cv_results_['mean_test_score']\n",
        "plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Iovwqv04PtHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Selected_features = ['Age', 'TravelAlone', 'Pclass_1', 'Pclass_2', 'Embarked_C',\n",
        "                     'Embarked_S', 'Sex_male', 'IsMinor']\n",
        "X = final_train[Selected_features]\n",
        "\n",
        "plt.subplots(figsize=(8, 5))\n",
        "sns.heatmap(X.corr(), annot=True, cmap=\"RdYlGn\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O0K6gUwVPv_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\n",
        "\n",
        "# create X (features) and y (response)\n",
        "X = final_train[Selected_features]\n",
        "y = final_train['Survived']\n",
        "\n",
        "# use train/test split with different random_state values\n",
        "# we can change the random_state values that changes the accuracy scores\n",
        "# the scores change a lot, this is why testing scores is a high-variance estimate\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
        "\n",
        "# check classification scores of logistic regression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
        "[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)\n",
        "print('Train/Test split results:')\n",
        "print(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))\n",
        "print(logreg.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_test, y_pred_proba))\n",
        "print(logreg.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))\n",
        "\n",
        "idx = np.min(np.where(tpr > 0.95)) # index of the first threshold for which the sensibility > 0.95\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='coral', label='ROC curve (area = %0.3f)' % auc(fpr, tpr))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot([0,fpr[idx]], [tpr[idx],tpr[idx]], 'k--', color='blue')\n",
        "plt.plot([fpr[idx],fpr[idx]], [0,tpr[idx]], 'k--', color='blue')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\n",
        "plt.ylabel('True Positive Rate (recall)', fontsize=14)\n",
        "plt.title('Receiver operating characteristic (ROC) curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Using a threshold of %.3f \" % thr[idx] + \"guarantees a sensitivity of %.3f \" % tpr[idx] +\n",
        "      \"and a specificity of %.3f\" % (1-fpr[idx]) +\n",
        "      \", i.e. a false positive rate of %.2f%%.\" % (np.array(fpr[idx])*100))"
      ],
      "metadata": {
        "id": "l1wqt3fhP3T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10-fold cross-validation logistic regression\n",
        "logreg = LogisticRegression()\n",
        "# Use cross_val_score function\n",
        "# We are passing the entirety of X and y, not X_train or y_train, it takes care of splitting the data\n",
        "# cv=10 for 10 folds\n",
        "# scoring = {'accuracy', 'neg_log_loss', 'roc_auc'} for evaluation metric - althought they are many\n",
        "scores_accuracy = cross_val_score(logreg, X, y, cv=10, scoring='accuracy')\n",
        "scores_log_loss = cross_val_score(logreg, X, y, cv=10, scoring='neg_log_loss')\n",
        "scores_auc = cross_val_score(logreg, X, y, cv=10, scoring='roc_auc')\n",
        "print('K-fold cross-validation results:')\n",
        "print(logreg.__class__.__name__+\" average accuracy is %2.3f\" % scores_accuracy.mean())\n",
        "print(logreg.__class__.__name__+\" average log_loss is %2.3f\" % -scores_log_loss.mean())\n",
        "print(logreg.__class__.__name__+\" average auc is %2.3f\" % scores_auc.mean())"
      ],
      "metadata": {
        "id": "36jxUCaxP4UF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "scoring = {'accuracy': 'accuracy', 'log_loss': 'neg_log_loss', 'auc': 'roc_auc'}\n",
        "\n",
        "modelCV = LogisticRegression()\n",
        "\n",
        "results = cross_validate(modelCV, X, y, cv=10, scoring=list(scoring.values()),\n",
        "                         return_train_score=False)\n",
        "\n",
        "print('K-fold cross-validation results:')\n",
        "for sc in range(len(scoring)):\n",
        "    print(modelCV.__class__.__name__+\" average %s: %.3f (+/-%.3f)\" % (list(scoring.keys())[sc], -results['test_%s' % list(scoring.values())[sc]].mean()\n",
        "                               if list(scoring.values())[sc]=='neg_log_loss'\n",
        "                               else results['test_%s' % list(scoring.values())[sc]].mean(),\n",
        "                               results['test_%s' % list(scoring.values())[sc]].std()))"
      ],
      "metadata": {
        "id": "MU9WldcAP84Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"Age\",\"Fare\",\"TravelAlone\",\"Pclass_1\",\"Pclass_2\",\"Embarked_C\",\"Embarked_S\",\"Sex_male\",\"IsMinor\"]\n",
        "X = final_train[cols]\n",
        "\n",
        "scoring = {'accuracy': 'accuracy', 'log_loss': 'neg_log_loss', 'auc': 'roc_auc'}\n",
        "\n",
        "modelCV = LogisticRegression()\n",
        "\n",
        "results = cross_validate(modelCV, final_train[cols], y, cv=10, scoring=list(scoring.values()),\n",
        "                         return_train_score=False)\n",
        "\n",
        "print('K-fold cross-validation results:')\n",
        "for sc in range(len(scoring)):\n",
        "    print(modelCV.__class__.__name__+\" average %s: %.3f (+/-%.3f)\" % (list(scoring.keys())[sc], -results['test_%s' % list(scoring.values())[sc]].mean()\n",
        "                               if list(scoring.values())[sc]=='neg_log_loss'\n",
        "                               else results['test_%s' % list(scoring.values())[sc]].mean(),\n",
        "                               results['test_%s' % list(scoring.values())[sc]].std()))"
      ],
      "metadata": {
        "id": "UyLRU5IQQAUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "X = final_train[Selected_features]\n",
        "\n",
        "param_grid = {'C': np.arange(1e-05, 3, 0.1)}\n",
        "scoring = {'Accuracy': 'accuracy', 'AUC': 'roc_auc', 'Log_loss': 'neg_log_loss'}\n",
        "\n",
        "gs = GridSearchCV(LogisticRegression(), return_train_score=True,\n",
        "                  param_grid=param_grid, scoring=scoring, cv=10, refit='Accuracy')\n",
        "\n",
        "gs.fit(X, y)\n",
        "results = gs.cv_results_\n",
        "\n",
        "print('='*20)\n",
        "print(\"best params: \" + str(gs.best_estimator_))\n",
        "print(\"best params: \" + str(gs.best_params_))\n",
        "print('best score:', gs.best_score_)\n",
        "print('='*20)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\",fontsize=16)\n",
        "\n",
        "plt.xlabel(\"Inverse of regularization strength: C\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.grid()\n",
        "\n",
        "ax = plt.axes()\n",
        "ax.set_xlim(0, param_grid['C'].max())\n",
        "ax.set_ylim(0.35, 0.95)\n",
        "\n",
        "# Get the regular numpy array from the MaskedArray\n",
        "X_axis = np.array(results['param_C'].data, dtype=float)\n",
        "\n",
        "for scorer, color in zip(list(scoring.keys()), ['g', 'k', 'b']):\n",
        "    for sample, style in (('train', '--'), ('test', '-')):\n",
        "        sample_score_mean = -results['mean_%s_%s' % (sample, scorer)] if scoring[scorer]=='neg_log_loss' else results['mean_%s_%s' % (sample, scorer)]\n",
        "        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n",
        "        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n",
        "                        sample_score_mean + sample_score_std,\n",
        "                        alpha=0.1 if sample == 'test' else 0, color=color)\n",
        "        ax.plot(X_axis, sample_score_mean, style, color=color,\n",
        "                alpha=1 if sample == 'test' else 0.7,\n",
        "                label=\"%s (%s)\" % (scorer, sample))\n",
        "\n",
        "    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
        "    best_score = -results['mean_test_%s' % scorer][best_index] if scoring[scorer]=='neg_log_loss' else results['mean_test_%s' % scorer][best_index]\n",
        "\n",
        "    # Plot a dotted vertical line at the best score for that scorer marked by x\n",
        "    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n",
        "            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n",
        "\n",
        "    # Annotate the best score for that scorer\n",
        "    ax.annotate(\"%0.2f\" % best_score,\n",
        "                (X_axis[best_index], best_score + 0.005))\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "4U2Mh-OWQHo2",
        "outputId": "2a2c267f-d315-47c7-c9df-4edda354fe14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'final_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ba6b56f2ae63>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSelected_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'final_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_test['Survived'] = log_clf.predict(final_test[Selected_features])\n",
        "final_test['PassengerId'] = test_df['PassengerId']\n",
        "\n",
        "submission = final_test[['PassengerId','Survived']]\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "submission.tail()"
      ],
      "metadata": {
        "id": "FVVa4WXdQw90"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}